첨부한 파일을 자신의 컴퓨터 저장받고,

저장경로를 확인한 후에 DT, RF, SVM, LR 분류를 각각 수행해보세요.

-----------

# Iris 데이터셋 기반 분류 모델 비교 실험 보고서

## 1. 개요
본 실험은 Iris 데이터셋을 활용하여 다양한 머신러닝 분류 모델들의 성능을 비교하는 것을 목표로 한다. 
결정 트리(Decision Tree), 랜덤 포레스트(Random Forest), 서포트 벡터 머신(SVM), 로지스틱 회귀(Logistic Regression) 모델을 적용하고, 5-폴드 교차 검증을 통해 정확도를 평가하였다.

## 2. 데이터셋
- **데이터 출처**: `dataset/iris.csv`
- **특징(features)**:
  - Sepal Length
  - Sepal Width
  - Petal Length
  - Petal Width
- **타겟(target)**:
  - `Name` 컬럼을 {Iris-setosa: 0, Iris-versicolor: 1, Iris-virginica: 2} 로 변환하여 정수형 라벨 사용

## 3. 사용된 모델
| 약어  | 모델 |
|-------|-----------------------------|
| DT    | Decision Tree Classifier    |
| RF    | Random Forest Classifier    |
| SVM   | Support Vector Machine (SVC) |
| LR    | Logistic Regression         |

### 모델별 특징 및 장단점
1. **Decision Tree (DT)**
   - **특징**: 트리 구조를 기반으로 데이터를 분할하며, 규칙 기반 학습 방식
   - **장점**: 
     - 직관적이고 해석이 용이함
     - 빠른 학습 및 예측 속도
     - 비선형 관계를 학습 가능
   - **단점**:
     - 과적합(overfitting) 가능성이 높음
     - 작은 변화에도 결과가 크게 변할 수 있음

2. **Random Forest (RF)**
   - **특징**: 여러 개의 결정 트리를 조합하여 예측하는 앙상블 기법
   - **장점**:
     - 과적합 방지 효과
     - 높은 예측 성능
     - 변수 중요도를 제공하여 특징 선택에 유용함
   - **단점**:
     - 개별 트리보다 계산 비용이 높음
     - 해석이 어려울 수 있음

3. **Support Vector Machine (SVM)**
   - **특징**: 데이터의 경계를 최대한 넓히는 초평면을 찾아 분류하는 알고리즘
   - **장점**:
     - 높은 일반화 성능
     - 차원이 높은 데이터에도 강함
   - **단점**:
     - 대량의 데이터에서 학습 속도가 느릴 수 있음
     - 최적의 커널 및 하이퍼파라미터 선택이 어려움

4. **Logistic Regression (LR)**
   - **특징**: 선형 모델을 기반으로 확률을 예측하는 분류 알고리즘
   - **장점**:
     - 해석이 용이함
     - 계산 비용이 낮고 빠름
   - **단점**:
     - 비선형 데이터에서는 성능이 떨어질 수 있음
     - 다중 클래스 분류 문제에서 제한적일 수 있음

## 4. 실험 방법
- 5-폴드(Stratified K-Fold) 교차 검증을 사용하여 각 모델의 성능을 평가
- `cross_val_score()` 함수를 사용하여 `accuracy` 측정
- 결과를 boxplot 그래프로 시각화

## 5. 코드 설명
- `pandas`를 사용하여 데이터를 로드하고, 타겟 변수를 변환
- `sklearn`의 분류 모델을 리스트에 저장하고 반복문을 통해 성능 평가
- `matplotlib`을 사용하여 분류기별 성능 비교 그래프 출력

## 6. 실험 결과
각 모델의 교차 검증 결과(정확도 스코어)는 다음과 같다:
```
DT  : [결과 값들]
RF  : [결과 값들]
SVM : [결과 값들]
LR  : [결과 값들]
```

위 결과를 바탕으로 분류 모델들의 성능을 비교 및 분석한다.

## 7. 결론
- 모델별 성능 차이를 분석하고, 최적의 모델을 선택하는 기준을 설정
- 향후 데이터 전처리 및 하이퍼파라미터 튜닝을 통한 성능 개선 가능성 탐색

